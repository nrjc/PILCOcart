\documentclass{article}
\renewcommand{\rmdefault}{psbx}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{textcomp}
\usepackage{eulervm}
\usepackage{amsmath}
\usepackage{amssymb}

\setlength{\textwidth}{160mm}
\setlength{\oddsidemargin}{0mm}
\setlength{\parindent}{0 mm}

\newcommand{\bff}{{\bf f}}
\newcommand{\bfm}{{\bf m}}
\newcommand{\bfx}{{\bf x}}
\newcommand{\E}{{\mathbb E}}
\newcommand{\V}{{\mathbb V}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\inv}{{^{-1}}}
\newcommand{\invt}{{^{-\top}}}

\title{Gaussian Processes with Uncertain Inputs:\\ Predictions and Derivatives}
\author{Carl Edward Rasmussen}
\date{November 24th, 2014}

\begin{document}

\maketitle


We want to model data with $E$ output coordinates, and use seperate
combinations of linear models and GPs to make predictions,
$a=1,\ldots,E$:
\[
f_a(x^*)\;=\;f_a^*\;\sim\;{\cal N}\big(\theta_a^\top x^*+k_a(x^*,\bfx)\beta_a,\;
k_a(x^*,x^*)-k_a(x^*,\bfx)(K_a+\Sigma_\varepsilon^a)^{-1}k_a(\bfx,x^*)\big),
\]
where the $E$ squared exponential covariance functions are
\begin{equation}
k_a(x,x')\;=\;s_a^2q(x, x',\Lambda_a,0), \text{\ \ where\ \ }a=1,\ldots,E,
\end{equation}
and $s_a^2$ are the signal variances and $\Lambda_a$ is a diagonal
matrix of squared length scales for GP number $a$. The noise variances
are $\Sigma_\varepsilon^a$. The inputs are $\bfx$ and the outputs
$y_a$ and we define $\beta_a=(K_a+\Sigma_\varepsilon^a)^{-1}(y_a-\theta_a^\top\bfx)$.


\subsection*{Predictions at uncertain inputs}

Consider making predictions from $a=1,\ldots,E$ GPs at $\bfx^*$ with specificati
on
\begin{equation}
p(\bfx^*|\bfm,\Sigma)\;\sim\;{\cal N}(\bfm, \Sigma).
\end{equation}
%
We have the following expressions for the predictive mean, variances
and input output covariances
\begin{align}
\E[\bff^*|\bfm,\Sigma]\;&=\;\int\big(s_a^2\beta_a^\top
q(x_i,\bfx^*,\Lambda_a,0)+\theta_a^\top\bfx^*\big){\cal N}(\bfx^*|\bfm,\Sigma)d\
bfx^*\;=\;s_a^2\beta_a^\top q^a+\theta_a^\top \bfm,\label{eq:m}\\
\C[x^*,f_a^*|\bfm,\Sigma]\;&=\;\int (x^*-\bfm)\big(s^2_a\beta_a^\top
q(\bfx,x^*,\Lambda_a,0)+\theta_a^\top x^*\big){\cal
  N}(x^*|\bfm,\Sigma)dx^*\nonumber\\
&=\;s^2_a\Sigma(\Lambda_a+\Sigma)^{-1}(\bfx-\bfm)\beta_aq^a+\Sigma\theta_a\;=\;
\Sigma C_a+\Sigma\theta_a,\label{eq:c}\\
\V[f_a^*|\bfm,\Sigma]\;&=\;\V[\E[f_a^*|x^*]|\bfm,\Sigma]+\E[\V[f_a^*|x^*]|\bfm,\Sigma]\nonumber\\
&=\;\V[s_a^2\beta_a^\top q(\bfx,x^*,\Lambda_a,0)+\theta_a^\top x^*]+\delta_{ab}\E[s_a^2-k_a(x^*,\bfx)(K_a+\Sigma_\varepsilon^a)^{-1}k_a(\bfx,x^*)]\label{eq:v}\\
&=\;s_a^2s_b^2\big[\beta_a^\top (Q^{ab}-q^aq^{b\top})\beta_b
+\delta_{ab}\big(s_a^{-2}-\operatorname{tr}((K_a+\Sigma_\varepsilon^a)^{-1}Q^{aa})\big)\big]
+C_a^\top\Sigma\theta_b+\theta_a^\top\Sigma C_b+\theta_a^\top\Sigma\theta_b,\nonumber\\
\text{\ \ where\ \ }\;q^a_i\;&=\;q(x_i,\bfm,\Lambda_a,\Sigma), \text{\ \ and\ \ }
Q^{ab}_{ij}\;=\;Q\big(x_i,x_j,\Lambda_a,\Lambda_b,0,\bfm,\Sigma\big).\nonumber
\end{align}
%
In the above we've made use of the following two functions
\begin{equation}
\begin{split}
q(x,x',\Lambda,V)\;\triangleq&\;|\Lambda^{-1}V+I|^{-1/2}\exp\big(-\tfrac{1}{2}(x-x')[\Lambda+V]^{-1}(x-x')\big),\\
Q(x,x',\Lambda_a,\Lambda_b,V, \mu, \Sigma)\;\triangleq&\;
c_1\exp\big(-\tfrac{1}{2}(x-x')^\top[\Lambda_a+\Lambda_b+2V]^{-1}(x-x')\big)\\
&\times\,\exp\big(-\tfrac{1}{2}(z-\mu)^\top\big[\big((\Lambda_a+V)^{-1}+(\Lambda_b+V)^{-1}\big)^{-1}+\Sigma\big]^{-1}(z-\mu)\big),\\
=&\;c_2\,q(x,\mu,\Lambda_a,V)\,q(\mu,x'\Lambda_b,V)\\
&\times\,\exp\big(\tfrac{1}{2}{\bf
  r}^\top\big[(\Lambda_a+V)^{-1}+(\Lambda_b+V)^{-1}+\Sigma^{-1}\big]^{-1}{\bf r}\big),\\
\text{where}&\left\{\begin{array}{l}
z\;=\;(\Lambda_b+V)(\Lambda_a+\Lambda_b+2V)^{-1}x+(\Lambda_a+V)(\Lambda_a+\Lambda_b+2V)^{-1}x'\\
{\bf r}\;=\;(\Lambda_a+V)^{-1}(x-\mu)+(\Lambda_b+V)^{-1}(x'-\mu)\\
c_1\;=\;\big|(\Lambda_a+V)(\Lambda_b+V)+(\Lambda_a+\Lambda_b+2V)\Sigma\big|^{-1/2}\big|\Lambda_a\Lambda_b\big|^{1/2}\;\\
c_2\;=\;\big|\big((\Lambda_a+V)^{-1}+(\Lambda_b+V)^{-1}\big)\Sigma+I\big|^{-1/2},\end{array}\right.
\end{split}
\end{equation}



\end{document}